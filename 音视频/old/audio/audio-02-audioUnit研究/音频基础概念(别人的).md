# iOS音频系列(一)--音频基础

 [原文链接](https://brownfeng.github.io/2016/07/25/iOS%E9%9F%B3%E9%A2%91%E7%B3%BB%E5%88%97(%E4%B8%80)/#comments)

前些日子由于项目需要,一直在研究iOS CoreAudio相关的内容.在这里记录一些笔记.现实生活中，我们听到的声音都是时间连续的，我们称为这种信号叫模拟信号。模拟信号需要进行数字化以后才能在计算机中使用。数字化的过程如下：

`采样 -> 量化 -> 编码`

通过获取间隔相同时间的某个模拟信号的值，然后对这些采样以后得到的值进行量化，然后使用一定的bit进行编码存储，整个过程结束后就会输出PCM数据。在iOS的Core Audio Services中使用的音频数据只能是线性PCM格式的音频数据，这是一种未进过压缩的音频数据格式。要理解整个过程就需要理解多个重要概念：采样频率和采样位数，比特率等。

### [](https://brownfeng.github.io/2016/07/25/iOS%E9%9F%B3%E9%A2%91%E7%B3%BB%E5%88%97(%E4%B8%80)/#%E9%87%87%E6%A0%B7%E9%A2%91%E7%8E%87 "采样频率")采样频率

采样频率是指单位时间内对声音模拟信号的采样次数。采样率类似于视频的帧数，比如电影的采样率是24Hz。当我们把采样到的一个个静止画面再以采样率同样的速度回放时，看到的就是连续的画面。同样的道理，把以44.1kHZ采样率记录的CD以同样的速率播放时，就能听到连续的声音。显然，这个采样率越高，听到的声音和看到的图像就越连贯。当然，人的听觉和视觉器官能分辨的采样率是有限的。对同一段声音，用20kHz和44.1kHz来采样，重放时，可能可以听出其中的差别，而基本上高于44.1kHZ采样的声音，比如说96kHz采样，绝大部分人已经觉察不到两种采样出来的声音的分别了。之所以使用44.1kHZ这个数值是因为经过了反复实验，人们发现这个采样精度最合适，低于这个值就会有较明显的损失，而高于这个值人的耳朵已经很难分辨，而且增大了数字音频所占用的空间。我们所使用的CD的采样标准就是44.1k。

### [](https://brownfeng.github.io/2016/07/25/iOS%E9%9F%B3%E9%A2%91%E7%B3%BB%E5%88%97(%E4%B8%80)/#%E9%87%87%E6%A0%B7%E4%BD%8D%E6%95%B0 "采样位数")采样位数

采样位数可以理解为采集卡处理声音的解析度。这个数值越大，解析度就越高，录制和回放的声音就越真实。我们首先要知道：电脑中的声音文件是用数字0和1来表示的。连续的模拟信号按一定的采样频率经数码脉冲取样后，每一个离散的脉冲信号被以一定的量化精度量化成一串二进制编码流，这串编码流的位数即为采样位数，也称为量化精度。

在电脑上录音的本质就是把模拟声音信号转换成数字信号。反之，在播放时则是把数字信号还原成模拟声音信号输出。采集卡的位是指采集卡在采集和播放声音文件时所使用数字声音信号的二进制位数。采集卡的位客观地反映了数字声音信号对输入声音信号描述的准确程度。例如，同一段音频信息，使用8bit描述单个采样信息，那么采样量化的范围就是0~255,如果使用16bit表示单个采样值,那么相应的采样量化的范围为0~64k。与8位采样位数相比，16位采样的动态范围的宽度更小，动态范围更宽广，声音的被记录的更加精细。一般CD使用的采样位数为16位。

16位二进制数的最小值是0000000000000000，最大值是1111111111111111，对应的十进制数就是0和65535，也就是最大和最小值之间的差值是65535，也就是说，它量化的模拟量的动态范围可以差65535，也就是96.32分贝（20 * lg65535）），所以，量化精度只和动态范围有关，和频率响应没关系。动态范围定在96分贝也是有道理的，人耳的无痛苦极限声压是90分贝，96分贝的动态范围在普通应用中足够使用，所以96分贝动态范围内的模拟波，经量化后，不会产生削波失真的。

> 所谓分贝是指两个相同的物理量（例A1和A0）之比取以10为底的对数并乘以10（或20）。N = 10lg(A1/A0) 分贝符号为”dB”，它是无量纲的。式中A0是基准量（或参考量），A是被量度量。被量度量和基准量之比取对数，这对数值称为被量度量的”级”。亦即用对数标度时，所得到的是比值，它代表被量度量比基准量高出多少”级”。

### [](https://brownfeng.github.io/2016/07/25/iOS%E9%9F%B3%E9%A2%91%E7%B3%BB%E5%88%97(%E4%B8%80)/#%E4%BD%8D%E9%80%9F-%E6%AF%94%E7%89%B9%E7%8E%87-%E7%A0%81%E7%8E%87 "位速/比特率/码率")位速/比特率/码率

位速/比特率/码率描述的都是一个东西，是指在一个数据流中每秒钟能通过的信息量。我们可能看到过音频文件用 “128–Kbps MP3” 或 “64–Kbps WMA” 进行描述的情形。Kbps 表示 “每秒千位数”，因此数值越大表示数据越多：128–Kbps MP3 音频文件包含的数据量是 64–Kbps WMA 文件的两倍，并占用两倍的空间。（不过在这种情况下，这两种文件听起来没什么两样。原因是什么呢？有些文件格式比其他文件能够更有效地利用数据， 64–Kbps WMA 文件的音质与 128–Kbps MP3 的音质相同。）需要了解的重要一点是，位速越高，信息量越大，对这些信息进行解码的处理量就越大，文件需要占用的空间也就越多。

从码率的计算公式中可以清楚的看出码率和采样位数的关系:

`码率=取样频率×量化精度×声道数`

> 一张CD,双声道,采样率44.1kHz，每个采样位数13bit，时长74分钟(4440秒)，则CD的容量为`13*2*44100*4440`约等于`640MB`。

### [](https://brownfeng.github.io/2016/07/25/iOS%E9%9F%B3%E9%A2%91%E7%B3%BB%E5%88%97(%E4%B8%80)/#VBR%E3%80%81ABR%E3%80%81CBR "VBR、ABR、CBR")VBR、ABR、CBR

VBR(Variable Bitrate)动态比特率。也就是没有固定的比特率，压缩软件在压缩时根据音频数据即时确定使用什么比特率。这是新发展的算法，他们将一首歌的复杂部分用高Bitrate编码，简单部分用低Bitrate编码。主意虽然不错，可惜新编码器的VBR算法很差，音质与CBR相去甚远。幸运的是， Lame完美地优化了VBR算法，使之成为MP3的最佳编码模式。这是以质量为前提兼顾文件大小的方式，推荐编码模式。

ABR(Average Bitrate)平均比特率，是VBR的一种插值参数。Lame针对CBR不佳的文件体积比和VBR生成文件大小不定的特点独创了这种编码模式。ABR也被称为“Safe VBR”，它是在指定的平均Bitrate内，以每50帧(30帧约1秒)为一段，低频和不敏感频率使用相对低的流量，高频和大动态表现时使用高流量。举例来说，当指定用192kbps ABR对一段wav文件进行编码时，Lame会将该文件的85%用192kbps固定编码，然后对剩余15%进行动态优化：复杂部分用高于192kbps 来编码、简单部分用低于192kbps来编码。与192kbps CBR相比，192kbps ABR在文件大小上相差不多，音质却提高不少。ABR编码在速度上是VBR编码的2到3倍，在128-256kbps范围内质量要好于CBR。可以做为 VBR和CBR的一种折衷选择。

CBR(Constant Bitrate)，常数比特率，指文件从头到尾都是一种位速率。相对于VBR和ABR来讲，它压缩出来的文件体积很大，但音质却不会有明显的提高。

### [](https://brownfeng.github.io/2016/07/25/iOS%E9%9F%B3%E9%A2%91%E7%B3%BB%E5%88%97(%E4%B8%80)/#PCM%E6%A0%BC%E5%BC%8F%E4%B8%8ELPCM%E6%A0%BC%E5%BC%8F "PCM格式与LPCM格式")PCM格式与LPCM格式

PCM（脉冲编码调制）是一种将模拟语音信号变换为数字信号的编码方式。主要经过3个过程：抽样、量化和编码。抽样过程将连续时间模拟信号变为离散时间、连续幅度的抽样信号，量化过程将抽样信号变为离散时间、离散幅度的数字信号，编码过程将量化后的信号编码成为一个二进制码组输出。

量化分为线性量化和非线性量化。线性量化在整个量化范围内，量化间隔均相等，称为LPCM。非线性量化采用不等的量化间隔。量化间隔数由编码的二进制位数决定。例如，CD采用16bit线性量化，则量化间隔数L=65536。位数（n)越多，精度越高，信噪比`SNR=6.02n+1.76`(dB)也越高。但编码的二进制位数不是无限制的，需要根据所需的数据率确定。比如：CD可以达到的数据率为2×44.1×16=1411.2Kbit/s。

总而言之，LPCM格式中的音频数据是未压缩的线性量化后的音频数据。

> 用iOS的官方文档中对几个关键词的解释：
> 
> *   A sample is single numerical value for a single channel.
> *   A frame is a collection of time-coincident samples. For instance, a stereo sound file has two samples per frame, one for the left channel and one for the right channel.
> *   A packet is a collection of one or more contiguous frames. In linear PCM audio, a packet is always a single frame. In compressed formats, it is typically more. A packet defines the smallest meaningful set of frames for a given audio data format.

### [](https://brownfeng.github.io/2016/07/25/iOS%E9%9F%B3%E9%A2%91%E7%B3%BB%E5%88%97(%E4%B8%80)/#%E5%8E%8B%E7%BC%A9%E8%BF%87%E7%9A%84%E9%9F%B3%E9%A2%91%E6%A0%BC%E5%BC%8F "压缩过的音频格式")压缩过的音频格式

在常见的音频格式对PCM原始帧进行封装时也是以frame帧为单位的，我们一般将压缩后的音频数据帧称为媒体帧，对应原始的PCM数据称为原始帧。每个媒体帧又分成head头，body数据体。在帧头中，会存储这个媒体帧中body部分的码率，采样率等解码必须的信息，因此每一个媒体帧都可以独立于文件存在和播放。在body中存储着一个或者多个媒体帧，这些媒体真是若干个PCM原始帧经过特定的压缩算法压缩得到的。通常情况下，我们将单位时间的媒体帧的个数称为帧率。

上文的采样率和帧率这两个概念都描述了音频媒体的“连续”性，二者的区别在于每个音频的媒体帧中会包含多个音频采样(多个PCM data)，如1个AAC帧中包含1024个采样。

> 在学习音频/视频相关内容之前,首先需要弄清楚的的是音频的文件类型和音频格式是有本质区别的.封装类型比如.ogg,音频格式比如.mp3.(具体的区别可以百度)